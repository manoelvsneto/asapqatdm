## Q5 – Respondents’ Answers: Treatment of Quality Attributes in Architecture (Translated from another language)

| Respondent | Response |
|-----------|----------|
| RESP1 | During architectural refinement rounds, we use a reference architecture model that defines the quality attributes we must meet. We design the solution architecture using these models as a reference and review it with peers. We iterate the designs until the excellence conditions of the reference model are satisfied. |
| RESP2 | In the first version, functionality must be guaranteed; afterwards, we address functional test automation, mutation testing, and performance improvements as the product evolves. We have a gateway requiring 100% unit test coverage from the start, and it evolves over time. |
| RESP3 | Minimum acceptance levels are agreed upon regarding functionality, performance, scalability, etc., and the first version is released only when these conditions are met. |
| RESP4 | There is no structured process for addressing quality during the conception of the first product version. Each team/sector/architect defines how to approach quality attributes, usually based on personal experience rather than theoretical foundations. |
| RESP5 | All quality pillars should be considered, but the ones I focus on most are: reliability, security, and maintainability. With these pillars well-structured, it’s possible to build a robust solution. Mapping these pillars allows us to define technical debts to maintain a healthy solution. |
| RESP6 | For the first version, we consider the physical structure of the project, e.g., a DDD-based design, to ensure that unit tests are applied. Apart from this, there is no concern with software quality in the architectural design of the first version. |
| RESP7 | Functional suitability is addressed through requirement gathering and story refinement during sprints. Efficiency is measured with tools like Dynatrace. Usability is handled by the UX team. Reliability and security are addressed by the security team. Maintainability is ensured via development standards applied from the beginning. Portability is supported through containerization. |
| RESP8 | Maximized usability for rapid testing, evolving structure enabling high maintainability, automated quality validation, and use of best practices and architectural standards. |
| RESP9 | In the first version, the software must deliver the expected outcomes (financial or otherwise). Therefore, the goal is to enable fast evolution with maintainability. Key points: clean and low-complexity code; well-written unit tests; proper exception handling without exposing errors to end users; clearly defined response times and external service error handling; asynchronous processing when possible; container-based deployment. |
| RESP10 | In the first software version, quality concerns are often deprioritized compared to other design aspects. Meeting delivery deadlines is the main priority, and only what fits within this timeframe is addressed in terms of quality. What cannot be addressed becomes technical debt. |
| RESP11 | For MVPs, we apply certain quality metrics. Every feature and MVP must be tested by QA and approved by the PO. These tests include UI and API testing, mostly automated for agility. Additionally, developers write unit tests, and SonarQube ensures a minimum 80% coverage. Architects also validate code through pull request policies in staging and production. |
| RESP12 | These notes reflect my view of the company's software products, which I either observed or helped design. I don’t consider the treatment of quality attributes to be adequate. There's great variability since the start of our "agile digital transformation." Something important is always sacrificed in the first version, often becoming backlog technical debt. The main goal is rapid delivery. There’s a lack of technical capacity to ensure minimal evolvability in maintainability and reliability. Usability is low in the first version and often remains poor. Performance and efficiency are neglected until production failures occur. Portability is only now being addressed. Security uses several mechanisms but falls short. Functional suitability is the most demanded attribute, though not always achieved. |
| RESP13 | Functional Suitability – The product should have a specific goal, not be multipurpose. Efficiency – Clearly defined minimum and maximum performance capacity. Compatibility – Must be compatible with all product modules and domains. Usability – The UI must provide a lightweight, objective experience that conveys security and stability. Reliability – Availability should be at least 99%, and the product must discreetly handle failures or instabilities. Security – Prevent unauthorized or accidental data access and comply with data protection laws. Maintainability – Minimize risks and impacts when changes are made. Portability – The product must be installable regardless of OS and easily switch between environments with minimal downtime. |
| RESP14 | I believe software quality should be addressed from the very first version, even if it’s just an MVP. Once the product proves viable, the next step is scaling — and if quality is poor, all the bugs from that first version will scale with it. |

