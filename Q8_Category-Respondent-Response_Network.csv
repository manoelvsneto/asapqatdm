Category,Respondent,Response
Unstructured Technical Evaluation,RESP2,"We discuss architecture during refinements and technical planning. The main concern is delivery. We are unable to accurately assess whether the architecture is efficient or scalable, nor do we have clarity on how to evolve it."
Unstructured Technical Evaluation,RESP4,"Architecture is discussed in technical meetings, but there is no clear criterion for assessing whether it is adequate. We work with what functions, but we do not really know if we are following a good architecture or what could be improved."
Unstructured Technical Evaluation,RESP12,"We conduct technical reviews and make decisions based on the developers’ and architects’ experience. Although we have pipelines, tests, and modern practices, we cannot say for sure whether the architecture is actually adequate or sustainable."
Unstructured Technical Evaluation,RESP14,"We evaluate the architecture based on deliveries and observed technical behaviors. Despite using internal standards and continuous integration, we still do not know exactly what needs to change to improve the architecture."
Focus on Functional Delivery,RESP3,"Architectural decisions are evaluated in the context of user stories and functionalities. Although we discuss technical alternatives, we cannot confidently say whether the architecture is suitable in the long term."
Focus on Functional Delivery,RESP6,"We discuss architecture during technical refinements. We usually solve problems as they arise. Despite having CI/CD and tests, we do not have a clear diagnosis of the system’s architectural quality."
Focus on Functional Delivery,RESP10,"Architecture is discussed at the beginning of projects and during refinements. We ensure that decisions are viable, but we are not sure whether they contribute to a good long-term architecture. There is a lack of a structured evaluation model."
Lack of Objective Criteria,RESP1,"Architecture is validated collaboratively, with a focus on technical functioning. Although the system is operating, we cannot measure whether the architecture is degrading or how to prioritize structural improvements."
Lack of Objective Criteria,RESP8,"Architectural decisions go through reviews with the architecture committee, especially during the initial phases of the project. We use good engineering practices, such as testing and version control, but we are not sure whether the architecture is good or needs adjustment."
Lack of Objective Criteria,RESP13,"There are architectural discussions within the squads and alignments with tech leads. Decisions are based on the team's best practices, but we lack objective criteria to determine whether the architecture is mature or has structural issues."
Continuous but Subjective Review,RESP5,"We have a recurring practice of reviewing technical solutions together with the team. Although we do code reviews and have automated tests, we do not have a clear method for determining whether the architecture is truly robust or needs adjustments."
Continuous but Subjective Review,RESP7,"We use architectural checkpoints and continuously track decisions. But even with these practices, we do not have sufficient metrics or evidence to say whether the architecture is healthy or not."
Continuous but Subjective Review,RESP9,"We evaluate architecture at project control points, such as the beginning of releases or technical definitions. We use internal tools and patterns, but we are unable to measure whether the architecture adheres to formal best practices."
Continuous but Subjective Review,RESP11,"We have a culture of technical review involving QA, developers, and architects. Decisions are guided by engineering practices, but we do not formally evaluate quality attributes. There is a lack of clarity about what truly defines good architecture."
